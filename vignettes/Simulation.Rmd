---
title: "Simulating data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r results='hide', warning=FALSE, message=FALSE}
library(genstats)
library(bigsnpr)
```

## Simulation without family history

The package offers different methods of simulating data. First, we are going to show how to simply get out the genotypes of N subjects and the genetic and full liabilities. We are using a small scale test, but if the data are going to be used for actual statistical analysis, we recommend that at least $10^4\times10^4$ data points are simulated. Further information about the parameters can be found here `?gen_sim`. 

```{r eval=FALSE}
gen_sim('simple_sim_example', N=1000, M=1000, K = 0.05, h2 = 0.5, C=50, block_size = 100, fam=FALSE)
```

Now there exists a rds file in the working directory with the data, which we will load.

```{r}
simple_data = snp_attach('simple_sim_example.rds')
class(simple_data)
```
Looking at the data the file contains a list. Here the genotypes (G), information for each SNP (map) and liabilities (fam) can be found.

```{r}
d1 = simple_data$genotypes[1:10,1:5]
d2 = simple_data$map[1:10,]
d3 = simple_data$fam[1:10,]

knitr::kables(
  list(knitr::kable(d1, col.names = c(1,2,3,4,5), caption = 'Genotypes'), 
       knitr::kable(d2, align = "c", digits = 3, caption = 'Map'), 
       knitr::kable(d3, align = "c", digits = 2, caption = 'Fam')))
```

Each SNP is sampled from the distribution $binom(2, MAF_j)$, the effect of a each causal SNP is sampled from the distribution $\mathcal{N}\left( 0, \frac{h^2}{c}\right)$ and each minor allele frequency (MAF) is sampled from the distribution $unif(0.01, 0.49)$. The liabilities is computed by $l_g =X \beta$ and $l_f = l_g + l_e$ with the following distributions. $l_g \sim \mathcal{N}(0, h^2),\ l_e \sim \mathcal{N}(0, 1-h^2)\ \text{and}\ l_f \sim \mathcal{N}(0,1)$. To clarify $h^2$ is defined as the variation in genetic liability.
Using the function dist_check() we can see whether the distribution of the full liabilities is as expected, which is standard normal. We are using a small test set and we cannot expect the the mean and variance to be close to 0 and 1.

```{r}
dist_check(simple_data)
```

We can see that the mean and variance differ a lot from 0 and 1, as stated this a a very small data set but with a larger simulation the distribution will become a lot closer to the expected values. The qqplot however resembles a normal distribution. It is now possible to perform GWAS for association analysis `vignette("GWAS")` or use the genotypes for prediction `vignette("Prediction")`.

## Simulation with family history

Simulation with family history is very similar to simulating without.

```{r eval=FALSE}
gen_sim('genetic_data', N=10000, M=10000, C=100, block_size = 1000, n_sib=2)
```

```{r message=FALSE}
family_data = snp_attach('genetic_data.rds')
knitr::kable(family_data$fam[1:10,2:16], align = "c", digits = 2)
```


We see here that we have a bit more family history, but the same same values each family member as we have for the subject. Again can we check the distribution of each full liability using the same function as before.

```{r}
dist_check(family_data)
```

Now that a larger data set have been simulated the mean and variance is a lot closer to the expected values of the liabilities and the qqplots for each liability clearly resembles a normal distribution. This data is therefore ready to be analysed using LTFH `vignette("LT-FH")` or used in predictive analysis `vignette("Prediction")`.

## Note on parrellelisation, block size and memory use.

The functions for the simulation have been optimized with parrellelisation and do this with all available cores as a standard. Depending on the computer running the simulation, the size of the simulation, the block size and amount of RAM this will take up a lot of memory of the computer. If a user specified amount of cores is preferred, this can be specified by running options(mc.cores = core_amount) where core_amount is the amount of cores available to R. Furthermore depending on the specified block size R will need to allocate quite a bit of memory, this can create an error on some computers depending on the RAM, it could be relevant to check <https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/memory.size>. If this doesn't fix the error, decreasing the block size and/or amount of cores is recommended.
